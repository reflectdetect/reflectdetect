{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pipline Detector"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f1d31c01e40c68f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-09T11:16:38.727213Z",
     "start_time": "2024-08-09T11:16:37.001218Z"
    }
   },
   "source": [
    "import json\n",
    "import math\n",
    "from exiftool import ExifToolHelper\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.util import img_as_ubyte"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Alignment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc915bd407054eaf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set Image paths for testing \n",
    "\n",
    "image_paths = [\n",
    "    r\"data\\example\\IMG_0040_1.tif\",\n",
    "    r\"data\\example\\IMG_0040_2.tif\",\n",
    "    r\"data\\example\\IMG_0040_3.tif\",\n",
    "    r\"data\\example\\IMG_0040_4.tif\",\n",
    "    r\"data\\example\\IMG_0040_5.tif\",\n",
    "]\n",
    "\n",
    "image_paths = [\"../../../\" + path for path in image_paths]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-09T11:16:35.792902Z",
     "start_time": "2024-08-09T11:16:35.787073Z"
    }
   },
   "id": "20b6fb2ba0aff0ac",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ExifToolExecuteError",
     "evalue": "execute returned a non-zero exit status: 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mExifToolExecuteError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ExifToolHelper() \u001B[38;5;28;01mas\u001B[39;00m et:\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m \u001B[43met\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../../../\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mimage_paths\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m      3\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m d\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m      4\u001B[0m             \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDict: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mv\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\reflectdetect\\venv\\Lib\\site-packages\\exiftool\\helper.py:292\u001B[0m, in \u001B[0;36mExifToolHelper.get_metadata\u001B[1;34m(self, files, params)\u001B[0m\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_metadata\u001B[39m(\u001B[38;5;28mself\u001B[39m, files: Union[\u001B[38;5;28mstr\u001B[39m, List], params: Optional[Union[\u001B[38;5;28mstr\u001B[39m, List]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List:\n\u001B[0;32m    276\u001B[0m \u001B[38;5;250m\t\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;124;03m\tReturn all metadata for the given files.\u001B[39;00m\n\u001B[0;32m    278\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m\t:return: The return value will have the format described in the documentation of :py:meth:`get_tags()`.\u001B[39;00m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;124;03m\t\"\"\"\u001B[39;00m\n\u001B[1;32m--> 292\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_tags\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\reflectdetect\\venv\\Lib\\site-packages\\exiftool\\helper.py:377\u001B[0m, in \u001B[0;36mExifToolHelper.get_tags\u001B[1;34m(self, files, tags, params)\u001B[0m\n\u001B[0;32m    374\u001B[0m exec_params\u001B[38;5;241m.\u001B[39mextend(final_files)\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 377\u001B[0m \tret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute_json\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mexec_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ExifToolOutputEmptyError:\n\u001B[0;32m    379\u001B[0m \t\u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\reflectdetect\\venv\\Lib\\site-packages\\exiftool\\exiftool.py:1176\u001B[0m, in \u001B[0;36mExifTool.execute_json\u001B[1;34m(self, *params)\u001B[0m\n\u001B[0;32m   1119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexecute_json\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mparams: Union[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbytes\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List:\n\u001B[0;32m   1120\u001B[0m \u001B[38;5;250m\t\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the given batch of parameters and parse the JSON output.\u001B[39;00m\n\u001B[0;32m   1121\u001B[0m \n\u001B[0;32m   1122\u001B[0m \u001B[38;5;124;03m\tThis method is similar to :py:meth:`execute()`.  It\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1173\u001B[0m \u001B[38;5;124;03m\t.. _Unpacking Argument Lists: https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists\u001B[39;00m\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;124;03m\t\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1176\u001B[0m \tresult \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m-j\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# stdout\u001B[39;00m\n\u001B[0;32m   1178\u001B[0m \t\u001B[38;5;66;03m# NOTE: I have decided NOT to check status code\u001B[39;00m\n\u001B[0;32m   1179\u001B[0m \t\u001B[38;5;66;03m# There are quite a few use cases where it's desirable to have continue-on-error behavior,\u001B[39;00m\n\u001B[0;32m   1180\u001B[0m \t\u001B[38;5;66;03m# as that is exiftool's default mode of operation.  exiftool normally just does what it can\u001B[39;00m\n\u001B[0;32m   1181\u001B[0m \t\u001B[38;5;66;03m# and tells you that it did all this and that, but some files didn't process.  In this case\u001B[39;00m\n\u001B[0;32m   1182\u001B[0m \t\u001B[38;5;66;03m# exit code is non-zero, but exiftool did SOMETHING.  I leave it up to the caller to figure\u001B[39;00m\n\u001B[0;32m   1183\u001B[0m \t\u001B[38;5;66;03m# out what was done or not done.\u001B[39;00m\n\u001B[0;32m   1186\u001B[0m \t\u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(result) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1187\u001B[0m \t\t\u001B[38;5;66;03m# the output from execute() can be empty under many relatively ambiguous situations\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \t\t\u001B[38;5;66;03m# * command has no files it worked on\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1196\u001B[0m \t\t\u001B[38;5;66;03m# Returning None was preferred, because it's the safest as it clearly indicates that nothing came back from execute(), but it means execute_json() doesn't always return JSON\u001B[39;00m\n\u001B[0;32m   1197\u001B[0m \t\t\u001B[38;5;66;03m# Raising an error is the current solution, as that clearly indicates that you used execute_json() expecting output, but got nothing\u001B[39;00m\n",
      "File \u001B[1;32m~\\reflectdetect\\venv\\Lib\\site-packages\\exiftool\\helper.py:135\u001B[0m, in \u001B[0;36mExifToolHelper.execute\u001B[1;34m(self, *params, **kwargs)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;66;03m# imitate the subprocess.run() signature.  check=True will check non-zero exit status\u001B[39;00m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_execute \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_last_status:\n\u001B[1;32m--> 135\u001B[0m \t\u001B[38;5;28;01mraise\u001B[39;00m ExifToolExecuteError(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_last_status, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_last_stdout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_last_stderr, str_bytes_params)\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[1;31mExifToolExecuteError\u001B[0m: execute returned a non-zero exit status: 1"
     ]
    }
   ],
   "source": [
    "with ExifToolHelper() as et:\n",
    "    for d in et.get_metadata(\"../../../\" + image_paths[0]):\n",
    "        for k, v in d.items():\n",
    "            print(f\"Dict: {k} = {v}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-09T11:16:41.827943Z",
     "start_time": "2024-08-09T11:16:40.362141Z"
    }
   },
   "id": "f7c8474ab318ce5f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'file_path': '../../../data\\\\example\\\\IMG_0040_1.tif', 'gps_latitude': 51.5536919, 'gps_longitude': 9.9010462, 'gps_altitude': 163.145, 'yaw': 0.5847416606989266, 'pitch': -0.3700787221340899, 'roll': 0.028103146529902822}, {'file_path': '../../../data\\\\example\\\\IMG_0040_2.tif', 'gps_latitude': 51.5536919, 'gps_longitude': 9.9010462, 'gps_altitude': 163.145, 'yaw': 0.5847416606989266, 'pitch': -0.3700787221340899, 'roll': 0.028103146529902822}, {'file_path': '../../../data\\\\example\\\\IMG_0040_3.tif', 'gps_latitude': 51.5536919, 'gps_longitude': 9.9010462, 'gps_altitude': 163.145, 'yaw': 0.5847416606989266, 'pitch': -0.3700787221340899, 'roll': 0.028103146529902822}, {'file_path': '../../../data\\\\example\\\\IMG_0040_4.tif', 'gps_latitude': 51.5536919, 'gps_longitude': 9.9010462, 'gps_altitude': 163.145, 'yaw': 0.5847416606989266, 'pitch': -0.3700787221340899, 'roll': 0.028103146529902822}, {'file_path': '../../../data\\\\example\\\\IMG_0040_5.tif', 'gps_latitude': 51.5536919, 'gps_longitude': 9.9010462, 'gps_altitude': 163.145, 'yaw': 0.5847416606989266, 'pitch': -0.3700787221340899, 'roll': 0.028103146529902822}]\n"
     ]
    }
   ],
   "source": [
    "# Function to extract EXIF data\n",
    "def extract_exif_data(image_path):\n",
    "    with ExifToolHelper() as et:\n",
    "        metadata = et.get_metadata(image_path)\n",
    "    return metadata[0]\n",
    "\n",
    "exif_data = []\n",
    "for image_path in image_paths:\n",
    "    metadata = extract_exif_data(image_path)\n",
    "    exif_data.append({\n",
    "        'file_path': image_path,\n",
    "        'gps_latitude': metadata.get('EXIF:GPSLatitude'),\n",
    "        'gps_longitude': metadata.get('EXIF:GPSLongitude'),\n",
    "        'gps_altitude': metadata.get('EXIF:GPSAltitude'),\n",
    "        'yaw': float(metadata.get('XMP:Yaw', 0)),  # Convert to float, default to 0 if not present\n",
    "        'pitch': float(metadata.get('XMP:Pitch', 0)),  # Convert to float, default to 0 if not present\n",
    "        'roll': float(metadata.get('XMP:Roll', 0)),  # Convert to float, default to 0 if not present\n",
    "    })\n",
    "print(exif_data)\n",
    "# Function to create a rotation matrix based on yaw, pitch, and roll\n",
    "def get_rotation_matrix(yaw, pitch, roll):\n",
    "    # Convert degrees to radians\n",
    "    yaw = np.deg2rad(yaw)\n",
    "    pitch = np.deg2rad(pitch)\n",
    "    roll = np.deg2rad(roll)\n",
    "\n",
    "    # Rotation matrices around the x, y, and z axes\n",
    "    Rx = np.array([[1, 0, 0],\n",
    "                   [0, np.cos(roll), -np.sin(roll)],\n",
    "                   [0, np.sin(roll), np.cos(roll)]])\n",
    "\n",
    "    Ry = np.array([[np.cos(pitch), 0, np.sin(pitch)],\n",
    "                   [0, 1, 0],\n",
    "                   [-np.sin(pitch), 0, np.cos(pitch)]])\n",
    "\n",
    "    Rz = np.array([[np.cos(yaw), -np.sin(yaw), 0],\n",
    "                   [np.sin(yaw), np.cos(yaw), 0],\n",
    "                   [0, 0, 1]])\n",
    "\n",
    "    # Combined rotation matrix\n",
    "    R = Rz @ Ry @ Rx\n",
    "\n",
    "    return R[:2, :3]\n",
    "\n",
    "# Function to align images\n",
    "def align_images(images, exif_data):\n",
    "    aligned_images = []\n",
    "\n",
    "    for idx, image_path in enumerate(images):\n",
    "        image = cv2.imread(image_path)\n",
    "        data = exif_data[idx]\n",
    "\n",
    "        # Extract orientation data\n",
    "        yaw = data['yaw']\n",
    "        pitch = data['pitch']\n",
    "        roll = data['roll']\n",
    "\n",
    "        # Get the rotation matrix\n",
    "        M = get_rotation_matrix(yaw, pitch, roll).astype(np.float32)\n",
    "\n",
    "        # Apply affine transformation\n",
    "        aligned_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "        aligned_images.append(aligned_image)\n",
    "\n",
    "    return aligned_images\n",
    "\n",
    "aligned_images = align_images(image_paths, exif_data)\n",
    "\n",
    "def overlay_images(images, alpha=0.5):\n",
    "    overlay = images[0].astype(np.float32)\n",
    "    for image in images[1:]:\n",
    "        overlay = cv2.addWeighted(overlay, alpha, image.astype(np.float32), alpha, 0)\n",
    "    overlay = cv2.normalize(overlay, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return overlay.astype(np.uint8)\n",
    "\n",
    "# Get the overlaid image\n",
    "overlaid_image = overlay_images(aligned_images, alpha=1.0 / len(aligned_images))\n",
    "\n",
    "# Save or display the overlaid image\n",
    "#output_path = \"overlaid_image.tif\"\n",
    "#cv2.imwrite(output_path, overlaid_image)\n",
    "cv2.imshow(\"Overlaid Image\", overlaid_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-09T11:17:12.643335Z",
     "start_time": "2024-08-09T11:17:08.647354Z"
    }
   },
   "id": "8df318a9d665e726",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Old Method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56332565485f8555"
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to normalize and equalize image intensity\n",
    "def normalize_and_equalize_image(image):\n",
    "    normalized = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    equalized = cv2.equalizeHist(normalized)\n",
    "    return equalized\n",
    "\n",
    "\n",
    "# Load and process the reference image (the first one)\n",
    "reference_image = cv2.imread(image_paths[0], cv2.IMREAD_GRAYSCALE)\n",
    "reference_image_processed = normalize_and_equalize_image(reference_image)\n",
    "\n",
    "# Initialize SIFT detector \n",
    "sift = cv2.SIFT_create(nfeatures=5000)\n",
    "\n",
    "# Detect and compute descriptors for the reference image\n",
    "keypoints_ref, descriptors_ref = sift.detectAndCompute(reference_image_processed, None)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)  # or pass empty dictionary\n",
    "\n",
    "# Create FLANN based matcher object\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "\n",
    "# Function to align an image to the reference image\n",
    "def align_image(image_path, keypoints_ref, descriptors_ref):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Normalize and equalize the image intensity\n",
    "    image_processed = normalize_and_equalize_image(image)\n",
    "\n",
    "    # Detect and compute descriptors for the image\n",
    "    keypoints, descriptors = sift.detectAndCompute(image_processed, None)\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = flann.knnMatch(descriptors, descriptors_ref, k=2)\n",
    "\n",
    "    # Apply Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:  # Adjusted ratio test threshold\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Ensure we have enough good matches\n",
    "    if len(good_matches) < 4:  # Minimum number of matches required for estimateAffinePartial2D\n",
    "        print(f\"Not enough matches found for {image_path}. Skipping alignment.\")\n",
    "        return None\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(good_matches):\n",
    "        points1[i, :] = keypoints[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints_ref[match.trainIdx].pt\n",
    "\n",
    "    # Find Euclidean transformation\n",
    "    h, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "\n",
    "    # Use the transformation to transform the image\n",
    "    height, width = reference_image.shape\n",
    "    aligned_image = cv2.warpAffine(image, h, (width, height))\n",
    "\n",
    "    return aligned_image\n",
    "\n",
    "\n",
    "# Align all images to the reference image\n",
    "aligned_images = [reference_image]\n",
    "for image_path in image_paths[1:]:\n",
    "    aligned_image = align_image(image_path, keypoints_ref, descriptors_ref)\n",
    "    if aligned_image is not None:\n",
    "        aligned_images.append(aligned_image)\n",
    "\n",
    "        # Display each aligned image\n",
    "        plt.figure()\n",
    "        plt.imshow(aligned_image, cmap='gray')\n",
    "        plt.title(f'Aligned Image: {image_path}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Combine aligned images (e.g., taking the mean of aligned images)\n",
    "combined_image = np.mean(np.array(aligned_images), axis=0).astype(np.uint8)\n",
    "\n",
    "# Save the combined image\n",
    "output_path = \"../../../\" + 'data/example/combined_image.tif'\n",
    "cv2.imwrite(output_path, combined_image)\n",
    "\n",
    "# Display the combined image\n",
    "plt.figure()\n",
    "plt.imshow(combined_image, cmap='gray')\n",
    "plt.title('Combined Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.288946Z"
    }
   },
   "id": "2fa7c1255fd8dcc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Panel Detector"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b77596129ba607b1"
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_panel_size_in_pixels(altitude, pixel_size, resolution, sensor_size_mm, focal_length_mm,\n",
    "                                   physical_panel_size):\n",
    "    \"\"\"\n",
    "    Calculate the expected size of an object in pixels based on camera parameters and object physical size.\n",
    "    \n",
    "    Parameters:\n",
    "        altitude (float): Altitude in meters.\n",
    "        pixel_size (float): Pixel size in meters.\n",
    "        resolution (tuple): Image resolution (width, height) in pixels.\n",
    "        sensor_size_mm (float): Sensor diagonal in millimeters.\n",
    "        focal_length_m (float): Focal length in millimeters.\n",
    "        physical_panel_size (tuple): Physical size of the object in meters (width, height).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Expected width and height of the object in pixels.\n",
    "    \"\"\"\n",
    "    # Convert sensor diagonal to meters\n",
    "    sensor_diagonal = sensor_size_mm / 1000  # Convert mm to m\n",
    "    focal_length = focal_length_mm / 1000\n",
    "\n",
    "    # Calculate horizontal and vertical Field of View (FoV)\n",
    "    fov_horizontal = 2 * math.atan(\n",
    "        (sensor_diagonal / (2 * math.sqrt(1 + (resolution[0] / resolution[1]) ** 2))) / focal_length)\n",
    "    fov_vertical = 2 * math.atan(\n",
    "        (sensor_diagonal / (2 * math.sqrt(1 + (resolution[1] / resolution[0]) ** 2))) / focal_length)\n",
    "\n",
    "    # Calculate scale in pixels per meter\n",
    "    scale_pixels_per_meter = resolution[1] / (altitude * math.tan(fov_vertical / 2))\n",
    "\n",
    "    # Calculate expected panel size in pixels\n",
    "    panel_width_pixels = np.intp(physical_panel_size[0] * scale_pixels_per_meter)\n",
    "    panel_height_pixels = np.intp(physical_panel_size[1] * scale_pixels_per_meter)\n",
    "\n",
    "    return panel_width_pixels, panel_height_pixels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.289944Z"
    }
   },
   "id": "a48c7a0a253c3a53",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def filter_by_variance(image, blur_kernel_size=15):\n",
    "    \"\"\"\n",
    "    Apply a variance filter to an image to enhance features.\n",
    "    \n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image.\n",
    "        blur_kernel_size (int): Size of the Gaussian blur kernel.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Filtered image.\n",
    "    \"\"\"\n",
    "    blur_non = cv2.GaussianBlur(image, (blur_kernel_size, blur_kernel_size), 2)\n",
    "    for i in range(10):\n",
    "        blur_non = cv2.GaussianBlur(blur_non, (blur_kernel_size, blur_kernel_size), 2)\n",
    "    last_blur_non = cv2.GaussianBlur(image, (blur_kernel_size, blur_kernel_size), 2)\n",
    "    return cv2.equalizeHist(img_as_ubyte((last_blur_non - blur_non) ** 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.289944Z"
    }
   },
   "id": "ffc965f86ecb1626",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def contour_solidity(contour):\n",
    "    \"\"\"\n",
    "    Calculate the solidity of a contour.\n",
    "    \n",
    "    Solidity is the ratio of contour area to convex hull area.\n",
    "    \n",
    "    Parameters:\n",
    "    contour (array-like): Contour points.\n",
    "\n",
    "    Returns:\n",
    "    float: Solidity value between 0 and 1.\n",
    "    \"\"\"\n",
    "    area = cv2.contourArea(contour)\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    if hull_area == 0:\n",
    "        return 0\n",
    "    return float(area) / hull_area"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.290945Z"
    }
   },
   "id": "287372867b6b003",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def scale_box(box, scale):\n",
    "    \"\"\"\n",
    "    Scale the size of a bounding box while keeping its center fixed.\n",
    "    \n",
    "    Parameters:\n",
    "        box (ndarray): Array of bounding box points.\n",
    "        scale (float): Scaling factor.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Scaled bounding box points.\n",
    "    \"\"\"\n",
    "    center = np.mean(box, axis=0)\n",
    "    scaled_box = scale * (box - center) + center\n",
    "    return scaled_box"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.291947Z"
    }
   },
   "id": "db8fd05b64868d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Given/known Camera parameters\n",
    "altitude = 16.3145  # Altitude in meters\n",
    "pixel_size = 3.45e-6  # Pixel size in meters\n",
    "resolution = (1456, 1088)  # Image resolution (width, height) in pixels\n",
    "sensor_size_mm = 6.3  # Sensor diagonal in millimeters\n",
    "focal_length_mm = 5.5  # Focal length in millimeters\n",
    "physical_panel_size = (1, 1)  # Physical size of the object in meters (width, height)\n",
    "\n",
    "panel_size_pixels = calculate_panel_size_in_pixels(\n",
    "    altitude, pixel_size, resolution, sensor_size_mm, focal_length_mm, physical_panel_size\n",
    ")\n",
    "print(\"Expected panel size in pixels:\", panel_size_pixels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.291947Z"
    }
   },
   "id": "237b89b4cdc4514",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "image_no = 0\n",
    "\n",
    "# Load images and preserve 16-bit format\n",
    "images16bit = [cv2.imread(image_path, cv2.IMREAD_UNCHANGED) for image_path in image_paths]\n",
    "\n",
    "# Normalize the image \n",
    "images16bit_norm = [cv2.normalize(image16bit, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX).astype(np.uint8)\n",
    "                    for image16bit in images16bit]\n",
    "\n",
    "images_eq_hist = [cv2.equalizeHist(image16bit_norm) for image16bit_norm in images16bit_norm]\n",
    "\n",
    "plt.style.use('classic')\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(images16bit[image_no], cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(images16bit_norm[image_no], cmap='gray')\n",
    "ax[1].set_title('Normalized Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(images_eq_hist[image_no], cmap='gray')\n",
    "ax[2].set_title('equalized histogram')\n",
    "ax[2].axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.292947Z"
    }
   },
   "id": "333555e2343f9e3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "image = images_eq_hist[image_no]\n",
    "\n",
    "variance = filter_by_variance(image)\n",
    "blur = cv2.medianBlur(variance, 5)\n",
    "ret, thresh1 = cv2.threshold(blur, 60, 255, cv2.THRESH_BINARY)\n",
    "masked = np.ma.array(thresh1, mask=thresh1, fill_value=0)\n",
    "\n",
    "plt.style.use('classic')\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].imshow(blur, cmap='gray')\n",
    "ax[0].set_title('Variance after Median Blur')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(thresh1, cmap='gray')\n",
    "ax[1].set_title('Thresholded Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(masked, cmap='gray')\n",
    "ax[2].set_title('Masked Image')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.292947Z"
    }
   },
   "id": "b080783c07f627e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# This Block can be deleted later in not required anymore\n",
    "\n",
    "# Ensure masked image is correctly obtained as a binary mask\n",
    "binary_mask = np.where(masked.mask, 0, 1).astype(np.uint8) * 255\n",
    "\n",
    "# Apply morphological operations to clean up the binary mask\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Find contours in the binary mask\n",
    "contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter contours based on size (e.g., minimum area) and solidity\n",
    "min_contour_area = (panel_size_pixels[0] * panel_size_pixels[1]) * 0.6  # Set to 60% of panels size\n",
    "min_solidity = 0.75  # Set a threshold for solidity to filter out non-homogeneous areas\n",
    "filtered_contours = [c for c in contours if\n",
    "                     cv2.contourArea(c) > min_contour_area and contour_solidity(c) > min_solidity]\n",
    "\n",
    "# Draw rotated bounding boxes on the original image (for visualization)\n",
    "image_with_bboxes = cv2.cvtColor(images16bit_norm[image_no],\n",
    "                                 cv2.COLOR_GRAY2BGR)  # Convert to BGR for colored bounding boxes \n",
    "\n",
    "# List to hold bounding box coordinates\n",
    "bounding_boxes = []\n",
    "\n",
    "scale_factor = 0.8  # Scale down the bounding box size by 20%\n",
    "\n",
    "for contour in filtered_contours:\n",
    "    # Get the minimum area rectangle for the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)  # Get the four points of the rectangle\n",
    "    box = np.intp(box)  # Convert to integer values\n",
    "\n",
    "    # Scale down the bounding box\n",
    "    scaled_box = scale_box(box, scale_factor)\n",
    "    scaled_box = np.intp(scaled_box)  # Convert to integer values\n",
    "\n",
    "    cv2.drawContours(image_with_bboxes, [scaled_box], 0, (255, 0, 0), 3)  # Draw the rectangle\n",
    "\n",
    "    # Save the bounding box coordinates\n",
    "    bounding_box = {\n",
    "        \"contour_index\": len(bounding_boxes),  # Index of the contour\n",
    "        \"coordinates\": scaled_box.tolist()  # Convert numpy array to list\n",
    "    }\n",
    "    bounding_boxes.append(bounding_box)\n",
    "\n",
    "# Save bounding box coordinates to a JSON file\n",
    "with open(\"bounding_boxes.json\", \"w\") as f:\n",
    "    json.dump(bounding_boxes, f, indent=4)\n",
    "\n",
    "# Visualize the result\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Equalized Histogram Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(binary_mask, cmap='gray')\n",
    "ax[1].set_title('Binary Mask with Morphological Operations')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(image_with_bboxes)\n",
    "ax[2].set_title('Image with Scaled Bounding Boxes')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.293945Z"
    }
   },
   "id": "535f5cbc86817eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# This Block can be deleted later in not required anymore\n",
    "\n",
    "plt.imshow(image_with_bboxes, cmap='gray')\n",
    "plt.title(f'IMG_0040_{image_no} with Scaled Bounding Boxes ')\n",
    "plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.293945Z"
    }
   },
   "id": "811c019b8efd4656",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def split_bounding_box(box, expected_aspect_ratio, threshold=0.1, spacing=10):\n",
    "    \"\"\"\n",
    "    Split the bounding box if its aspect ratio deviates significantly from the expected aspect ratio,\n",
    "    and space apart the resulting boxes by a specified amount.\n",
    "    \n",
    "    Parameters:\n",
    "        box (ndarray): Array of bounding box points.\n",
    "        expected_aspect_ratio (float): The expected aspect ratio of the panels.\n",
    "        threshold (float): The acceptable threshold for aspect ratio deviation.\n",
    "        spacing (int): The amount of spacing to add between the resulting boxes.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of bounding boxes (ndarray).\n",
    "    \"\"\"\n",
    "    rect = cv2.minAreaRect(box)\n",
    "    width, height = rect[1]\n",
    "\n",
    "    if width == 0 or height == 0:\n",
    "        return [box]\n",
    "\n",
    "    # Calculate the aspect ratio of the bounding box\n",
    "    aspect_ratio = width / height if width > height else height / width\n",
    "\n",
    "    # Compare aspect ratio with expected aspect ratio\n",
    "    if abs(aspect_ratio - expected_aspect_ratio) / expected_aspect_ratio > threshold:\n",
    "        # Determine if width or height should be split\n",
    "        if width > height:\n",
    "            new_width = width / 2\n",
    "            size1 = (new_width, height)\n",
    "            size2 = (new_width, height)\n",
    "            offset = (spacing / 2) * np.array([np.cos(np.deg2rad(rect[2])), np.sin(np.deg2rad(rect[2]))])\n",
    "            center1 = (rect[0][0] - new_width / 2 * np.cos(np.deg2rad(rect[2])),\n",
    "                       rect[0][1] - new_width / 2 * np.sin(np.deg2rad(rect[2]))) - offset\n",
    "            center2 = (rect[0][0] + new_width / 2 * np.cos(np.deg2rad(rect[2])),\n",
    "                       rect[0][1] + new_width / 2 * np.sin(np.deg2rad(rect[2]))) + offset\n",
    "        else:\n",
    "            new_height = height / 2\n",
    "            size1 = (width, new_height)\n",
    "            size2 = (width, new_height)\n",
    "            offset = (spacing / 2) * np.array([np.sin(np.deg2rad(rect[2])), -np.cos(np.deg2rad(rect[2]))])\n",
    "            center1 = (rect[0][0] - new_height / 2 * np.sin(np.deg2rad(rect[2])),\n",
    "                       rect[0][1] + new_height / 2 * np.cos(np.deg2rad(rect[2]))) - offset\n",
    "            center2 = (rect[0][0] + new_height / 2 * np.sin(np.deg2rad(rect[2])),\n",
    "                       rect[0][1] - new_height / 2 * np.cos(np.deg2rad(rect[2]))) + offset\n",
    "\n",
    "        # Create two new bounding boxes\n",
    "        box1 = cv2.boxPoints((center1, size1, rect[2]))\n",
    "        box2 = cv2.boxPoints((center2, size2, rect[2]))\n",
    "\n",
    "        return [np.intp(box1), np.intp(box2)]\n",
    "\n",
    "    return [box]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.294945Z"
    }
   },
   "id": "e7c564589a946b84",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ensure masked image is correctly obtained as a binary mask\n",
    "binary_mask = np.where(masked.mask, 0, 1).astype(np.uint8) * 255\n",
    "\n",
    "# Apply morphological operations to clean up the binary mask\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Find contours in the binary mask\n",
    "contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "# Function to calculate the solidity of a contour\n",
    "def contour_solidity(contour):\n",
    "    area = cv2.contourArea(contour)\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    if hull_area == 0:\n",
    "        return 0\n",
    "    return float(area) / hull_area\n",
    "\n",
    "\n",
    "# Filter contours based on size (e.g., minimum area) and solidity\n",
    "min_contour_area = (panel_size_pixels[0] * panel_size_pixels[1]) * 0.6  # Set this based on your specific needs\n",
    "min_solidity = 0.75  # Set a threshold for solidity to filter out non-homogeneous areas\n",
    "filtered_contours = [c for c in contours if\n",
    "                     cv2.contourArea(c) > min_contour_area and contour_solidity(c) > min_solidity]\n",
    "\n",
    "# Expected aspect ratio based on physical panel size\n",
    "expected_aspect_ratio = physical_panel_size[0] / physical_panel_size[1]\n",
    "threshold = 0.1  # Threshold for aspect ratio deviation\n",
    "spacing = 20  # Amount of spacing to add between the resulting boxes\n",
    "\n",
    "# Draw rotated bounding boxes on the original image (for visualization)\n",
    "image_with_bboxes = cv2.cvtColor(images16bit_norm[image_no],\n",
    "                                 cv2.COLOR_GRAY2BGR)  # Convert to BGR for colored bounding boxes\n",
    "\n",
    "# List to hold bounding box coordinates\n",
    "bounding_boxes = []\n",
    "\n",
    "for contour in filtered_contours:\n",
    "    # Get the minimum area rectangle for the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)  # Get the four points of the rectangle\n",
    "    box = np.intp(box)  # Convert to integer values\n",
    "\n",
    "    # Scale down the bounding box\n",
    "    scaled_box = scale_box(box, scale_factor)\n",
    "    scaled_box = np.intp(scaled_box)  # Convert to integer values\n",
    "\n",
    "    # Split bounding box if necessary and space apart\n",
    "    boxes = split_bounding_box(scaled_box, expected_aspect_ratio, threshold, spacing)\n",
    "\n",
    "    for bbox in boxes:\n",
    "        cv2.drawContours(image_with_bboxes, [bbox], 0, (255, 0, 0), 3)  # Draw the rectangle\n",
    "        # Save the bounding box coordinates\n",
    "        bounding_box = {\n",
    "            \"contour_index\": len(bounding_boxes),  # Index of the contour\n",
    "            \"coordinates\": bbox.tolist()  # Convert numpy array to list\n",
    "        }\n",
    "        bounding_boxes.append(bounding_box)\n",
    "\n",
    "# Save bounding box coordinates to a JSON file\n",
    "with open(\"bounding_boxes.json\", \"w\") as f:\n",
    "    json.dump(bounding_boxes, f, indent=4)\n",
    "\n",
    "# Visualize the result\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Equalized Histogram Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(binary_mask, cmap='gray')\n",
    "ax[1].set_title('Binary Mask with Morphological Operations')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(image_with_bboxes)\n",
    "ax[2].set_title('Image with Scaled and Split Bounding Boxes')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.294945Z"
    }
   },
   "id": "2d4f3fa41fe63168",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.295945Z"
    }
   },
   "id": "aca2d79e36b88b3d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.imshow(binary_mask, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.295945Z"
    }
   },
   "id": "26afe5ac60cc024d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.imshow(image_with_bboxes, cmap='gray')\n",
    "plt.title(f'IMG_0040_{image_no} with Scaled Bounding Boxes ')\n",
    "plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.296948Z"
    }
   },
   "id": "f807e39df9e5d2ff",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
