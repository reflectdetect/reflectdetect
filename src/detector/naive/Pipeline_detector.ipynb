{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pipline Detector"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f1d31c01e40c68f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:45:52.076443Z",
     "start_time": "2024-05-22T18:45:52.074034Z"
    }
   },
   "source": [
    "import json\n",
    "import math\n",
    "from exiftool import ExifToolHelper\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.util import img_as_ubyte"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Alignment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc915bd407054eaf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set Image paths for testing \n",
    "\n",
    "image_paths = [\n",
    "    r\"data\\example\\IMG_0040_1.tif\",\n",
    "    r\"data\\example\\IMG_0040_2.tif\",\n",
    "    r\"data\\example\\IMG_0040_3.tif\",\n",
    "    r\"data\\example\\IMG_0040_4.tif\",\n",
    "    r\"data\\example\\IMG_0040_5.tif\",\n",
    "]\n",
    "\n",
    "image_paths = [\"../../../\" + path for path in image_paths]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:45:52.088029Z",
     "start_time": "2024-05-22T18:45:52.085453Z"
    }
   },
   "id": "20b6fb2ba0aff0ac",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict: SourceFile = ../../../data/example/IMG_0040_1.tif\n",
      "Dict: ExifTool:ExifToolVersion = 12.85\n",
      "Dict: File:FileName = IMG_0040_1.tif\n",
      "Dict: File:Directory = ../../../data/example\n",
      "Dict: File:FileSize = 3176902\n",
      "Dict: File:FileModifyDate = 2024:05:18 12:10:56+02:00\n",
      "Dict: File:FileAccessDate = 2024:05:22 20:44:27+02:00\n",
      "Dict: File:FileCreateDate = 2024:05:17 23:32:22+02:00\n",
      "Dict: File:FilePermissions = 100666\n",
      "Dict: File:FileType = TIFF\n",
      "Dict: File:FileTypeExtension = TIF\n",
      "Dict: File:MIMEType = image/tiff\n",
      "Dict: File:ExifByteOrder = II\n",
      "Dict: EXIF:SubfileType = 0\n",
      "Dict: EXIF:ImageWidth = 1456\n",
      "Dict: EXIF:ImageHeight = 1088\n",
      "Dict: EXIF:BitsPerSample = 16\n",
      "Dict: EXIF:Compression = 1\n",
      "Dict: EXIF:PhotometricInterpretation = 1\n",
      "Dict: EXIF:Make = MicaSense\n",
      "Dict: EXIF:Model = RedEdge-P\n",
      "Dict: EXIF:StripOffsets = (Binary data 78 bytes, use -b option to extract)\n",
      "Dict: EXIF:Orientation = 1\n",
      "Dict: EXIF:SamplesPerPixel = 1\n",
      "Dict: EXIF:RowsPerStrip = 100\n",
      "Dict: EXIF:StripByteCounts = (Binary data 76 bytes, use -b option to extract)\n",
      "Dict: EXIF:PlanarConfiguration = 1\n",
      "Dict: EXIF:Software = v1.3.1\n",
      "Dict: EXIF:ModifyDate = 2024:04:18 12:18:13\n",
      "Dict: EXIF:ExposureTime = 0.001962664\n",
      "Dict: EXIF:FNumber = 2.8\n",
      "Dict: EXIF:ExposureProgram = 2\n",
      "Dict: EXIF:ISOSpeed = 1600\n",
      "Dict: EXIF:ExifVersion = 0230\n",
      "Dict: EXIF:DateTimeOriginal = 2024:04:18 12:18:13\n",
      "Dict: EXIF:CreateDate = 2024:04:18 12:18:13\n",
      "Dict: EXIF:MeteringMode = 1\n",
      "Dict: EXIF:FocalLength = 5.5\n",
      "Dict: EXIF:SubSecTime = 280976410\n",
      "Dict: EXIF:FocalPlaneXResolution = 289.855072\n",
      "Dict: EXIF:FocalPlaneYResolution = 289.855072\n",
      "Dict: EXIF:FocalPlaneResolutionUnit = 4\n",
      "Dict: EXIF:SerialNumber = PR03-2117902-MS\n",
      "Dict: EXIF:GPSVersionID = 2 2 0 0\n",
      "Dict: EXIF:GPSLatitudeRef = N\n",
      "Dict: EXIF:GPSLatitude = 51.5536919\n",
      "Dict: EXIF:GPSLongitudeRef = E\n",
      "Dict: EXIF:GPSLongitude = 9.9010462\n",
      "Dict: EXIF:GPSAltitudeRef = 0\n",
      "Dict: EXIF:GPSAltitude = 163.145\n",
      "Dict: EXIF:GPSDOP = 0\n",
      "Dict: EXIF:BlackLevelRepeatDim = 2 2\n",
      "Dict: EXIF:BlackLevel = 3844 3844 3844 3844\n",
      "Dict: EXIF:OpcodeList3 = (Binary data 104 bytes, use -b option to extract)\n",
      "Dict: XMP:XMPToolkit = XMP Core 4.4.0\n",
      "Dict: XMP:About = Pix4D Camera Information\n",
      "Dict: XMP:RigName = RedEdge-P\n",
      "Dict: XMP:BandName = Blue\n",
      "Dict: XMP:CentralWavelength = 475\n",
      "Dict: XMP:WavelengthFWHM = 32\n",
      "Dict: XMP:ModelType = perspective\n",
      "Dict: XMP:PrincipalPoint = 2.34142,1.82654\n",
      "Dict: XMP:PerspectiveFocalLength = 5.45716446\n",
      "Dict: XMP:PerspectiveFocalLengthUnits = mm\n",
      "Dict: XMP:PerspectiveDistortion = ['-0.090873309999999999', '0.12924350000000001', '-0.022418839999999999', '-0.0011185699999999999', -0.0006624949]\n",
      "Dict: XMP:VignettingPolynomial2DName = 0,0,0,1,0,2,0,3,0,4,0,5,1,0,1,1,1,2,1,3,1,4,2,0,2,1,2,2,2,3,3,0,3,1,3,2,4,0,4,1,5,0\n",
      "Dict: XMP:VignettingPolynomial2D = 0.510443,0.624129,-1.032047,0.847790,-0.326883,-0.133211,1.398379,-0.346565,0.679290,-0.738617,0.568030,-0.677497,0.526477,-0.623158,-0.172194,-1.954489,-0.291953,0.381084,1.411968,0.046391,-0.266914\n",
      "Dict: XMP:BandSensitivity = 0.20139149466378142\n",
      "Dict: XMP:RigRelatives = 0.260106, -0.083754, 0.014678\n",
      "Dict: XMP:RigTranslations = [-48.30699, 0.175626, -0.46636]\n",
      "Dict: XMP:RigTranslationsUnits = mm\n",
      "Dict: XMP:RigCameraIndex = 0\n",
      "Dict: XMP:RigRelativesReferenceRigCameraIndex = 1\n",
      "Dict: XMP:GPSXYAccuracy = 1.0989999771118164\n",
      "Dict: XMP:GPSZAccuracy = 1.4019999504089355\n",
      "Dict: XMP:Irradiance = 19.071090902697012\n",
      "Dict: XMP:IrradianceYaw = 33.503229263519295\n",
      "Dict: XMP:IrradiancePitch = -21.203948865878075\n",
      "Dict: XMP:IrradianceRoll = 1.6101916872011568\n",
      "Dict: XMP:BootTimestamp = 686\n",
      "Dict: XMP:RadiometricCalibration = ['0.00018907980000000001', 9.079776e-09, 2.160492e-05]\n",
      "Dict: XMP:ImagerTemperatureC = 16.49\n",
      "Dict: XMP:FlightId = ykwlbQxGM31cN3FlytiQ\n",
      "Dict: XMP:CaptureId = OUZgmN1QI4HoEiLzoa3b\n",
      "Dict: XMP:TriggerMethod = 4\n",
      "Dict: XMP:PressureAlt = 0\n",
      "Dict: XMP:DarkRowValue = [3844, 3844, 3844, 3844]\n",
      "Dict: XMP:Serial = DA05-2209245-WC\n",
      "Dict: XMP:SwVersion = v1.2.4\n",
      "Dict: XMP:CenterWavelength = 475\n",
      "Dict: XMP:Bandwidth = 32\n",
      "Dict: XMP:TimeStamp = 689815\n",
      "Dict: XMP:SpectralIrradiance = 19.071090902697012\n",
      "Dict: XMP:HorizontalIrradiance = 25.480950406435255\n",
      "Dict: XMP:DirectIrradiance = 13.730727018737703\n",
      "Dict: XMP:ScatteredIrradiance = 15.302464055048794\n",
      "Dict: XMP:SolarElevation = 0.83499417608946891\n",
      "Dict: XMP:SolarAzimuth = 3.5201036823172314\n",
      "Dict: XMP:EstimatedDirectLightVector = ['-0.26862157645306589', '-0.93401002112800602', '-0.23551587865010623']\n",
      "Dict: XMP:Yaw = 0.58474166069892664\n",
      "Dict: XMP:Pitch = -0.37007872213408988\n",
      "Dict: XMP:Roll = 0.028103146529902822\n",
      "Dict: Composite:Aperture = 2.8\n",
      "Dict: Composite:ImageSize = 1456 1088\n",
      "Dict: Composite:Megapixels = 1.584128\n",
      "Dict: Composite:ScaleFactor35efl = 6.89977357978919\n",
      "Dict: Composite:ShutterSpeed = 0.001962664\n",
      "Dict: Composite:SubSecModifyDate = 2024:04:18 12:18:13.280976410\n",
      "Dict: Composite:GPSAltitude = 163.145\n",
      "Dict: Composite:GPSLatitude = 51.5536919\n",
      "Dict: Composite:GPSLongitude = 9.9010462\n",
      "Dict: Composite:CircleOfConfusion = 0.00435467342245521\n",
      "Dict: Composite:FOV = 50.752246326259\n",
      "Dict: Composite:FocalLength35efl = 37.9487546888405\n",
      "Dict: Composite:GPSPosition = 51.5536919 9.9010462\n",
      "Dict: Composite:HyperfocalDistance = 2.4809142685332\n"
     ]
    }
   ],
   "source": [
    "with ExifToolHelper() as et:\n",
    "    for d in et.get_metadata(\"../../../\" + image_paths[0]):\n",
    "        for k, v in d.items():\n",
    "            print(f\"Dict: {k} = {v}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:45:52.441612Z",
     "start_time": "2024-05-22T18:45:52.117785Z"
    }
   },
   "id": "f7c8474ab318ce5f",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to extract EXIF data\n",
    "def extract_exif_data(image_path):\n",
    "    with ExifToolHelper() as et:\n",
    "        metadata = et.get_metadata(image_path)\n",
    "    return metadata[0]\n",
    "\n",
    "exif_data = []\n",
    "for image_path in image_paths:\n",
    "    metadata = extract_exif_data(image_path)\n",
    "    exif_data.append({\n",
    "        'file_path': image_path,\n",
    "        'gps_latitude': metadata.get('EXIF:GPSLatitude'),\n",
    "        'gps_longitude': metadata.get('EXIF:GPSLongitude'),\n",
    "        'gps_altitude': metadata.get('EXIF:GPSAltitude'),\n",
    "        'yaw': float(metadata.get('XMP:Yaw', 0)),  # Convert to float, default to 0 if not present\n",
    "        'pitch': float(metadata.get('XMP:Pitch', 0)),  # Convert to float, default to 0 if not present\n",
    "        'roll': float(metadata.get('XMP:Roll', 0)),  # Convert to float, default to 0 if not present\n",
    "    })\n",
    "\n",
    "# Function to create a rotation matrix based on yaw, pitch, and roll\n",
    "def get_rotation_matrix(yaw, pitch, roll):\n",
    "    # Convert degrees to radians\n",
    "    yaw = np.deg2rad(yaw)\n",
    "    pitch = np.deg2rad(pitch)\n",
    "    roll = np.deg2rad(roll)\n",
    "\n",
    "    # Rotation matrices around the x, y, and z axes\n",
    "    Rx = np.array([[1, 0, 0],\n",
    "                   [0, np.cos(roll), -np.sin(roll)],\n",
    "                   [0, np.sin(roll), np.cos(roll)]])\n",
    "\n",
    "    Ry = np.array([[np.cos(pitch), 0, np.sin(pitch)],\n",
    "                   [0, 1, 0],\n",
    "                   [-np.sin(pitch), 0, np.cos(pitch)]])\n",
    "\n",
    "    Rz = np.array([[np.cos(yaw), -np.sin(yaw), 0],\n",
    "                   [np.sin(yaw), np.cos(yaw), 0],\n",
    "                   [0, 0, 1]])\n",
    "\n",
    "    # Combined rotation matrix\n",
    "    R = Rz @ Ry @ Rx\n",
    "\n",
    "    return R[:2, :3]\n",
    "\n",
    "# Function to align images\n",
    "def align_images(images, exif_data):\n",
    "    aligned_images = []\n",
    "\n",
    "    for idx, image_path in enumerate(images):\n",
    "        image = cv2.imread(image_path)\n",
    "        data = exif_data[idx]\n",
    "\n",
    "        # Extract orientation data\n",
    "        yaw = data['yaw']\n",
    "        pitch = data['pitch']\n",
    "        roll = data['roll']\n",
    "\n",
    "        # Get the rotation matrix\n",
    "        M = get_rotation_matrix(yaw, pitch, roll).astype(np.float32)\n",
    "\n",
    "        # Apply affine transformation\n",
    "        aligned_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "        aligned_images.append(aligned_image)\n",
    "\n",
    "    return aligned_images\n",
    "\n",
    "aligned_images = align_images(image_paths, exif_data)\n",
    "\n",
    "def overlay_images(images, alpha=0.5):\n",
    "    overlay = images[0].astype(np.float32)\n",
    "    for image in images[1:]:\n",
    "        overlay = cv2.addWeighted(overlay, alpha, image.astype(np.float32), alpha, 0)\n",
    "    overlay = cv2.normalize(overlay, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return overlay.astype(np.uint8)\n",
    "\n",
    "# Get the overlaid image\n",
    "overlaid_image = overlay_images(aligned_images, alpha=1.0 / len(aligned_images))\n",
    "\n",
    "# Save or display the overlaid image\n",
    "#output_path = \"overlaid_image.tif\"\n",
    "#cv2.imwrite(output_path, overlaid_image)\n",
    "cv2.imshow(\"Overlaid Image\", overlaid_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T19:27:29.567673Z",
     "start_time": "2024-05-22T19:27:23.541413Z"
    }
   },
   "id": "8df318a9d665e726",
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Old Method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56332565485f8555"
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to normalize and equalize image intensity\n",
    "def normalize_and_equalize_image(image):\n",
    "    normalized = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    equalized = cv2.equalizeHist(normalized)\n",
    "    return equalized\n",
    "\n",
    "\n",
    "# Load and process the reference image (the first one)\n",
    "reference_image = cv2.imread(image_paths[0], cv2.IMREAD_GRAYSCALE)\n",
    "reference_image_processed = normalize_and_equalize_image(reference_image)\n",
    "\n",
    "# Initialize SIFT detector \n",
    "sift = cv2.SIFT_create(nfeatures=5000)\n",
    "\n",
    "# Detect and compute descriptors for the reference image\n",
    "keypoints_ref, descriptors_ref = sift.detectAndCompute(reference_image_processed, None)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)  # or pass empty dictionary\n",
    "\n",
    "# Create FLANN based matcher object\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "\n",
    "# Function to align an image to the reference image\n",
    "def align_image(image_path, keypoints_ref, descriptors_ref):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Normalize and equalize the image intensity\n",
    "    image_processed = normalize_and_equalize_image(image)\n",
    "\n",
    "    # Detect and compute descriptors for the image\n",
    "    keypoints, descriptors = sift.detectAndCompute(image_processed, None)\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = flann.knnMatch(descriptors, descriptors_ref, k=2)\n",
    "\n",
    "    # Apply Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:  # Adjusted ratio test threshold\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Ensure we have enough good matches\n",
    "    if len(good_matches) < 4:  # Minimum number of matches required for estimateAffinePartial2D\n",
    "        print(f\"Not enough matches found for {image_path}. Skipping alignment.\")\n",
    "        return None\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(good_matches):\n",
    "        points1[i, :] = keypoints[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints_ref[match.trainIdx].pt\n",
    "\n",
    "    # Find Euclidean transformation\n",
    "    h, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "\n",
    "    # Use the transformation to transform the image\n",
    "    height, width = reference_image.shape\n",
    "    aligned_image = cv2.warpAffine(image, h, (width, height))\n",
    "\n",
    "    return aligned_image\n",
    "\n",
    "\n",
    "# Align all images to the reference image\n",
    "aligned_images = [reference_image]\n",
    "for image_path in image_paths[1:]:\n",
    "    aligned_image = align_image(image_path, keypoints_ref, descriptors_ref)\n",
    "    if aligned_image is not None:\n",
    "        aligned_images.append(aligned_image)\n",
    "\n",
    "        # Display each aligned image\n",
    "        plt.figure()\n",
    "        plt.imshow(aligned_image, cmap='gray')\n",
    "        plt.title(f'Aligned Image: {image_path}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Combine aligned images (e.g., taking the mean of aligned images)\n",
    "combined_image = np.mean(np.array(aligned_images), axis=0).astype(np.uint8)\n",
    "\n",
    "# Save the combined image\n",
    "output_path = \"../../../\" + 'data/example/combined_image.tif'\n",
    "cv2.imwrite(output_path, combined_image)\n",
    "\n",
    "# Display the combined image\n",
    "plt.figure()\n",
    "plt.imshow(combined_image, cmap='gray')\n",
    "plt.title('Combined Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.288946Z"
    }
   },
   "id": "2fa7c1255fd8dcc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Panel Detector"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b77596129ba607b1"
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_panel_size_in_pixels(altitude, pixel_size, resolution, sensor_size_mm, focal_length_mm,\n",
    "                                   physical_panel_size):\n",
    "    \"\"\"\n",
    "    Calculate the expected size of an object in pixels based on camera parameters and object physical size.\n",
    "    \n",
    "    Parameters:\n",
    "        altitude (float): Altitude in meters.\n",
    "        pixel_size (float): Pixel size in meters.\n",
    "        resolution (tuple): Image resolution (width, height) in pixels.\n",
    "        sensor_size_mm (float): Sensor diagonal in millimeters.\n",
    "        focal_length_m (float): Focal length in millimeters.\n",
    "        physical_panel_size (tuple): Physical size of the object in meters (width, height).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Expected width and height of the object in pixels.\n",
    "    \"\"\"\n",
    "    # Convert sensor diagonal to meters\n",
    "    sensor_diagonal = sensor_size_mm / 1000  # Convert mm to m\n",
    "    focal_length = focal_length_mm / 1000\n",
    "\n",
    "    # Calculate horizontal and vertical Field of View (FoV)\n",
    "    fov_horizontal = 2 * math.atan(\n",
    "        (sensor_diagonal / (2 * math.sqrt(1 + (resolution[0] / resolution[1]) ** 2))) / focal_length)\n",
    "    fov_vertical = 2 * math.atan(\n",
    "        (sensor_diagonal / (2 * math.sqrt(1 + (resolution[1] / resolution[0]) ** 2))) / focal_length)\n",
    "\n",
    "    # Calculate scale in pixels per meter\n",
    "    scale_pixels_per_meter = resolution[1] / (altitude * math.tan(fov_vertical / 2))\n",
    "\n",
    "    # Calculate expected panel size in pixels\n",
    "    panel_width_pixels = np.intp(physical_panel_size[0] * scale_pixels_per_meter)\n",
    "    panel_height_pixels = np.intp(physical_panel_size[1] * scale_pixels_per_meter)\n",
    "\n",
    "    return panel_width_pixels, panel_height_pixels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.289944Z"
    }
   },
   "id": "a48c7a0a253c3a53",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def filter_by_variance(image, blur_kernel_size=15):\n",
    "    \"\"\"\n",
    "    Apply a variance filter to an image to enhance features.\n",
    "    \n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image.\n",
    "        blur_kernel_size (int): Size of the Gaussian blur kernel.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Filtered image.\n",
    "    \"\"\"\n",
    "    blur_non = cv2.GaussianBlur(image, (blur_kernel_size, blur_kernel_size), 2)\n",
    "    for i in range(10):\n",
    "        blur_non = cv2.GaussianBlur(blur_non, (blur_kernel_size, blur_kernel_size), 2)\n",
    "    last_blur_non = cv2.GaussianBlur(image, (blur_kernel_size, blur_kernel_size), 2)\n",
    "    return cv2.equalizeHist(img_as_ubyte((last_blur_non - blur_non) ** 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.289944Z"
    }
   },
   "id": "ffc965f86ecb1626",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def contour_solidity(contour):\n",
    "    \"\"\"\n",
    "    Calculate the solidity of a contour.\n",
    "    \n",
    "    Solidity is the ratio of contour area to convex hull area.\n",
    "    \n",
    "    Parameters:\n",
    "    contour (array-like): Contour points.\n",
    "\n",
    "    Returns:\n",
    "    float: Solidity value between 0 and 1.\n",
    "    \"\"\"\n",
    "    area = cv2.contourArea(contour)\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    if hull_area == 0:\n",
    "        return 0\n",
    "    return float(area) / hull_area"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.290945Z"
    }
   },
   "id": "287372867b6b003",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def scale_box(box, scale):\n",
    "    \"\"\"\n",
    "    Scale the size of a bounding box while keeping its center fixed.\n",
    "    \n",
    "    Parameters:\n",
    "        box (ndarray): Array of bounding box points.\n",
    "        scale (float): Scaling factor.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Scaled bounding box points.\n",
    "    \"\"\"\n",
    "    center = np.mean(box, axis=0)\n",
    "    scaled_box = scale * (box - center) + center\n",
    "    return scaled_box"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.291947Z"
    }
   },
   "id": "db8fd05b64868d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Given/known Camera parameters\n",
    "altitude = 16.3145  # Altitude in meters\n",
    "pixel_size = 3.45e-6  # Pixel size in meters\n",
    "resolution = (1456, 1088)  # Image resolution (width, height) in pixels\n",
    "sensor_size_mm = 6.3  # Sensor diagonal in millimeters\n",
    "focal_length_mm = 5.5  # Focal length in millimeters\n",
    "physical_panel_size = (1, 1)  # Physical size of the object in meters (width, height)\n",
    "\n",
    "panel_size_pixels = calculate_panel_size_in_pixels(\n",
    "    altitude, pixel_size, resolution, sensor_size_mm, focal_length_mm, physical_panel_size\n",
    ")\n",
    "print(\"Expected panel size in pixels:\", panel_size_pixels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.291947Z"
    }
   },
   "id": "237b89b4cdc4514",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "image_no = 0\n",
    "\n",
    "# Load images and preserve 16-bit format\n",
    "images16bit = [cv2.imread(image_path, cv2.IMREAD_UNCHANGED) for image_path in image_paths]\n",
    "\n",
    "# Normalize the image \n",
    "images16bit_norm = [cv2.normalize(image16bit, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX).astype(np.uint8)\n",
    "                    for image16bit in images16bit]\n",
    "\n",
    "images_eq_hist = [cv2.equalizeHist(image16bit_norm) for image16bit_norm in images16bit_norm]\n",
    "\n",
    "plt.style.use('classic')\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(images16bit[image_no], cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(images16bit_norm[image_no], cmap='gray')\n",
    "ax[1].set_title('Normalized Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(images_eq_hist[image_no], cmap='gray')\n",
    "ax[2].set_title('equalized histogram')\n",
    "ax[2].axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.292947Z"
    }
   },
   "id": "333555e2343f9e3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "image = images_eq_hist[image_no]\n",
    "\n",
    "variance = filter_by_variance(image)\n",
    "blur = cv2.medianBlur(variance, 5)\n",
    "ret, thresh1 = cv2.threshold(blur, 60, 255, cv2.THRESH_BINARY)\n",
    "masked = np.ma.array(thresh1, mask=thresh1, fill_value=0)\n",
    "\n",
    "plt.style.use('classic')\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].imshow(blur, cmap='gray')\n",
    "ax[0].set_title('Variance after Median Blur')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(thresh1, cmap='gray')\n",
    "ax[1].set_title('Thresholded Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(masked, cmap='gray')\n",
    "ax[2].set_title('Masked Image')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.292947Z"
    }
   },
   "id": "b080783c07f627e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# This Block can be deleted later in not required anymore\n",
    "\n",
    "# Ensure masked image is correctly obtained as a binary mask\n",
    "binary_mask = np.where(masked.mask, 0, 1).astype(np.uint8) * 255\n",
    "\n",
    "# Apply morphological operations to clean up the binary mask\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Find contours in the binary mask\n",
    "contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter contours based on size (e.g., minimum area) and solidity\n",
    "min_contour_area = (panel_size_pixels[0] * panel_size_pixels[1]) * 0.6  # Set to 60% of panels size\n",
    "min_solidity = 0.75  # Set a threshold for solidity to filter out non-homogeneous areas\n",
    "filtered_contours = [c for c in contours if\n",
    "                     cv2.contourArea(c) > min_contour_area and contour_solidity(c) > min_solidity]\n",
    "\n",
    "# Draw rotated bounding boxes on the original image (for visualization)\n",
    "image_with_bboxes = cv2.cvtColor(images16bit_norm[image_no],\n",
    "                                 cv2.COLOR_GRAY2BGR)  # Convert to BGR for colored bounding boxes \n",
    "\n",
    "# List to hold bounding box coordinates\n",
    "bounding_boxes = []\n",
    "\n",
    "scale_factor = 0.8  # Scale down the bounding box size by 20%\n",
    "\n",
    "for contour in filtered_contours:\n",
    "    # Get the minimum area rectangle for the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)  # Get the four points of the rectangle\n",
    "    box = np.intp(box)  # Convert to integer values\n",
    "\n",
    "    # Scale down the bounding box\n",
    "    scaled_box = scale_box(box, scale_factor)\n",
    "    scaled_box = np.intp(scaled_box)  # Convert to integer values\n",
    "\n",
    "    cv2.drawContours(image_with_bboxes, [scaled_box], 0, (255, 0, 0), 3)  # Draw the rectangle\n",
    "\n",
    "    # Save the bounding box coordinates\n",
    "    bounding_box = {\n",
    "        \"contour_index\": len(bounding_boxes),  # Index of the contour\n",
    "        \"coordinates\": scaled_box.tolist()  # Convert numpy array to list\n",
    "    }\n",
    "    bounding_boxes.append(bounding_box)\n",
    "\n",
    "# Save bounding box coordinates to a JSON file\n",
    "with open(\"bounding_boxes.json\", \"w\") as f:\n",
    "    json.dump(bounding_boxes, f, indent=4)\n",
    "\n",
    "# Visualize the result\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Equalized Histogram Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(binary_mask, cmap='gray')\n",
    "ax[1].set_title('Binary Mask with Morphological Operations')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(image_with_bboxes)\n",
    "ax[2].set_title('Image with Scaled Bounding Boxes')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.293945Z"
    }
   },
   "id": "535f5cbc86817eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# This Block can be deleted later in not required anymore\n",
    "\n",
    "plt.imshow(image_with_bboxes, cmap='gray')\n",
    "plt.title(f'IMG_0040_{image_no} with Scaled Bounding Boxes ')\n",
    "plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.293945Z"
    }
   },
   "id": "811c019b8efd4656",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def split_bounding_box(box, expected_aspect_ratio, threshold=0.1, spacing=10):\n",
    "    \"\"\"\n",
    "    Split the bounding box if its aspect ratio deviates significantly from the expected aspect ratio,\n",
    "    and space apart the resulting boxes by a specified amount.\n",
    "    \n",
    "    Parameters:\n",
    "        box (ndarray): Array of bounding box points.\n",
    "        expected_aspect_ratio (float): The expected aspect ratio of the panels.\n",
    "        threshold (float): The acceptable threshold for aspect ratio deviation.\n",
    "        spacing (int): The amount of spacing to add between the resulting boxes.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of bounding boxes (ndarray).\n",
    "    \"\"\"\n",
    "    rect = cv2.minAreaRect(box)\n",
    "    width, height = rect[1]\n",
    "\n",
    "    if width == 0 or height == 0:\n",
    "        return [box]\n",
    "\n",
    "    # Calculate the aspect ratio of the bounding box\n",
    "    aspect_ratio = width / height if width > height else height / width\n",
    "\n",
    "    # Compare aspect ratio with expected aspect ratio\n",
    "    if abs(aspect_ratio - expected_aspect_ratio) / expected_aspect_ratio > threshold:\n",
    "        # Determine if width or height should be split\n",
    "        if width > height:\n",
    "            new_width = width / 2\n",
    "            size1 = (new_width, height)\n",
    "            size2 = (new_width, height)\n",
    "            offset = (spacing / 2) * np.array([np.cos(np.deg2rad(rect[2])), np.sin(np.deg2rad(rect[2]))])\n",
    "            center1 = (rect[0][0] - new_width / 2 * np.cos(np.deg2rad(rect[2])),\n",
    "                       rect[0][1] - new_width / 2 * np.sin(np.deg2rad(rect[2]))) - offset\n",
    "            center2 = (rect[0][0] + new_width / 2 * np.cos(np.deg2rad(rect[2])),\n",
    "                       rect[0][1] + new_width / 2 * np.sin(np.deg2rad(rect[2]))) + offset\n",
    "        else:\n",
    "            new_height = height / 2\n",
    "            size1 = (width, new_height)\n",
    "            size2 = (width, new_height)\n",
    "            offset = (spacing / 2) * np.array([np.sin(np.deg2rad(rect[2])), -np.cos(np.deg2rad(rect[2]))])\n",
    "            center1 = (rect[0][0] - new_height / 2 * np.sin(np.deg2rad(rect[2])),\n",
    "                       rect[0][1] + new_height / 2 * np.cos(np.deg2rad(rect[2]))) - offset\n",
    "            center2 = (rect[0][0] + new_height / 2 * np.sin(np.deg2rad(rect[2])),\n",
    "                       rect[0][1] - new_height / 2 * np.cos(np.deg2rad(rect[2]))) + offset\n",
    "\n",
    "        # Create two new bounding boxes\n",
    "        box1 = cv2.boxPoints((center1, size1, rect[2]))\n",
    "        box2 = cv2.boxPoints((center2, size2, rect[2]))\n",
    "\n",
    "        return [np.intp(box1), np.intp(box2)]\n",
    "\n",
    "    return [box]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.294945Z"
    }
   },
   "id": "e7c564589a946b84",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ensure masked image is correctly obtained as a binary mask\n",
    "binary_mask = np.where(masked.mask, 0, 1).astype(np.uint8) * 255\n",
    "\n",
    "# Apply morphological operations to clean up the binary mask\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Find contours in the binary mask\n",
    "contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "# Function to calculate the solidity of a contour\n",
    "def contour_solidity(contour):\n",
    "    area = cv2.contourArea(contour)\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    if hull_area == 0:\n",
    "        return 0\n",
    "    return float(area) / hull_area\n",
    "\n",
    "\n",
    "# Filter contours based on size (e.g., minimum area) and solidity\n",
    "min_contour_area = (panel_size_pixels[0] * panel_size_pixels[1]) * 0.6  # Set this based on your specific needs\n",
    "min_solidity = 0.75  # Set a threshold for solidity to filter out non-homogeneous areas\n",
    "filtered_contours = [c for c in contours if\n",
    "                     cv2.contourArea(c) > min_contour_area and contour_solidity(c) > min_solidity]\n",
    "\n",
    "# Expected aspect ratio based on physical panel size\n",
    "expected_aspect_ratio = physical_panel_size[0] / physical_panel_size[1]\n",
    "threshold = 0.1  # Threshold for aspect ratio deviation\n",
    "spacing = 20  # Amount of spacing to add between the resulting boxes\n",
    "\n",
    "# Draw rotated bounding boxes on the original image (for visualization)\n",
    "image_with_bboxes = cv2.cvtColor(images16bit_norm[image_no],\n",
    "                                 cv2.COLOR_GRAY2BGR)  # Convert to BGR for colored bounding boxes\n",
    "\n",
    "# List to hold bounding box coordinates\n",
    "bounding_boxes = []\n",
    "\n",
    "for contour in filtered_contours:\n",
    "    # Get the minimum area rectangle for the contour\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)  # Get the four points of the rectangle\n",
    "    box = np.intp(box)  # Convert to integer values\n",
    "\n",
    "    # Scale down the bounding box\n",
    "    scaled_box = scale_box(box, scale_factor)\n",
    "    scaled_box = np.intp(scaled_box)  # Convert to integer values\n",
    "\n",
    "    # Split bounding box if necessary and space apart\n",
    "    boxes = split_bounding_box(scaled_box, expected_aspect_ratio, threshold, spacing)\n",
    "\n",
    "    for bbox in boxes:\n",
    "        cv2.drawContours(image_with_bboxes, [bbox], 0, (255, 0, 0), 3)  # Draw the rectangle\n",
    "        # Save the bounding box coordinates\n",
    "        bounding_box = {\n",
    "            \"contour_index\": len(bounding_boxes),  # Index of the contour\n",
    "            \"coordinates\": bbox.tolist()  # Convert numpy array to list\n",
    "        }\n",
    "        bounding_boxes.append(bounding_box)\n",
    "\n",
    "# Save bounding box coordinates to a JSON file\n",
    "with open(\"bounding_boxes.json\", \"w\") as f:\n",
    "    json.dump(bounding_boxes, f, indent=4)\n",
    "\n",
    "# Visualize the result\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Equalized Histogram Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(binary_mask, cmap='gray')\n",
    "ax[1].set_title('Binary Mask with Morphological Operations')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(image_with_bboxes)\n",
    "ax[2].set_title('Image with Scaled and Split Bounding Boxes')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.294945Z"
    }
   },
   "id": "2d4f3fa41fe63168",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.295945Z"
    }
   },
   "id": "aca2d79e36b88b3d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.imshow(binary_mask, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.295945Z"
    }
   },
   "id": "26afe5ac60cc024d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.imshow(image_with_bboxes, cmap='gray')\n",
    "plt.title(f'IMG_0040_{image_no} with Scaled Bounding Boxes ')\n",
    "plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-22T18:45:53.296948Z"
    }
   },
   "id": "f807e39df9e5d2ff",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
